import sys
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig
import nltk
import string
from nltk.tokenize import wordpunct_tokenize
import os
import re
import gc
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"


# Setup
nltk.download('punkt')
device = "cuda" if torch.cuda.is_available() else "cpu"
torch.cuda.empty_cache()
print(f"Using device: {device}")
sys.stdout.flush()

os.environ["HF_TOKEN"] = "Hugging_Face_Token"

model_names = [
    "ALLaM-AI/ALLaM-7B-Instruct-preview",
    "mistralai/Mistral-7B-Instruct-v0.3",
    "meta-llama/Llama-3.1-8B-Instruct"
]

grammar_model_name = "meta-llama/Llama-3.1-8B-Instruct"


# Define test cases for different scores
arabic_test_cases = {
    "1": """
Ø§Ù†Ø§ ÙŠØ±ÙˆØ­ Ø³ÙˆÙ‚ Ù…Ø¹ Ø§Ø®ÙŠ Ø§Ù…Ø¨Ø§Ø±Ø­ Ù†Ø´ØªØ±ÙŠ Ø®Ø¶Ø§Ø± ÙˆÙÙˆØ§ÙƒÙ‡ Ù„ÙƒÙ† Ù…Ø§ ÙÙŠ Ø´ÙŠ ÙƒØ«ÙŠØ± Ù‡Ù†Ø§Ùƒ ÙˆÙƒÙ…Ø§Ù† Ù…Ø§ Ù†Ø¹Ø±Ù ÙˆÙŠÙ† Ù†Ø±ÙˆØ­ Ø¨Ø¹Ø¯ÙŠÙ† Ø§Ø®ÙŠ Ù‚Ø§Ù„ Ù†Ù…Ø´ÙŠ Ø¨Ø³ Ø³ÙŠØ§Ø±Ù‡ ÙƒØ§Ù†Øª ÙˆØ§Ù‚ÙÙ‡ ÙÙŠ Ù†Øµ Ø´Ø§Ø±Ø¹ ÙˆÙ…Ø§ Ù†Ù‚Ø¯Ø± Ù†Ø¹Ø¯ÙŠ ÙˆÙƒØ§Ù† ÙÙŠ Ù†Ø§Ø³ ÙƒØ«ÙŠØ± ØªØµØ±Ø® ÙˆØ§Ø­Ù†Ø§ Ø®ÙÙ†Ø§ ÙˆØ±Ø¬Ø¹Ù†Ø§ Ù…Ø´ÙŠ Ù„Ù„Ø¨ÙŠØª Ø¨Ø³Ø±Ø¹Ù‡ ÙƒØªÙŠØ± Ù…Ø§ Ø§ÙƒÙ„Ù†Ø§ Ø´ÙŠ ÙˆØ¬Ù„Ø³Ù†Ø§ Ù†ÙˆÙ… Ø¨Ø¯ÙˆÙ† Ù†ØºØ³Ù„ ÙŠØ¯Ù†Ø§ Ø§Ùˆ Ù†ØºÙŠØ± Ù‡Ø¯ÙˆÙ…Ù†Ø§.
""",  # Grammar Score: 0 â€” incorrect verb conjugation, tense inconsistency, lack of punctuation, fragmented sentences, poor structure

    "2": """
Ø°Ù‡Ø¨Øª Ù…Ø¹ Ø£Ø®ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø³ÙˆÙ‚ Ø¨Ø§Ù„Ø£Ù…Ø³ Ù„Ø´Ø±Ø§Ø¡ Ø¨Ø¹Ø¶ Ø§Ù„Ø®Ø¶Ø±ÙˆØ§Øª ÙˆØ§Ù„ÙÙˆØ§ÙƒÙ‡ØŒ ÙˆÙ„ÙƒÙ† ÙˆØ§Ø¬Ù‡ØªÙ†Ø§ Ù…Ø´ÙƒÙ„Ø© Ø¹Ù†Ø¯Ù…Ø§ ØªØ¹Ø·Ù„Øª Ø§Ù„Ø³ÙŠØ§Ø±Ø© Ø¨Ø´ÙƒÙ„ Ù…ÙØ§Ø¬Ø¦ ÙÙŠ Ù…Ù†ØªØµÙ Ø§Ù„Ø·Ø±ÙŠÙ‚. Ø­Ø§ÙˆÙ„Ù†Ø§ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…ÙŠÙƒØ§Ù†ÙŠÙƒÙŠ Ù„ÙƒÙ†Ù‡ Ù„Ù… ÙŠÙƒÙ† Ù…ØªØ§Ø­Ù‹Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„ÙˆÙ‚ØªØŒ Ù…Ù…Ø§ Ø§Ø¶Ø·Ø±Ù†Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„ÙØªØ±Ø© Ø·ÙˆÙŠÙ„Ø©. Ø¨Ø¹Ø¯ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø³ÙŠØ§Ø±Ø©ØŒ Ø¹Ø¯Ù†Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†Ø²Ù„ ÙÙŠ ÙˆÙ‚Øª Ù…ØªØ£Ø®Ø±ØŒ ÙˆÙƒÙ†Ø§ Ù…Ø±Ù‡Ù‚ÙŠÙ† Ù„Ø¯Ø±Ø¬Ø© Ø£Ù†Ù†Ø§ Ù„Ù… Ù†Ø­Ø¶Ø± Ø§Ù„Ø¹Ø´Ø§Ø¡ ÙƒØ§Ù„Ù…Ø¹ØªØ§Ø¯. Ø§ÙƒØªÙÙŠÙ†Ø§ Ø¨ØªÙ†Ø§ÙˆÙ„ Ø¨Ø¹Ø¶ Ø§Ù„Ø¨Ø³ÙƒÙˆÙŠØª ÙˆØ´Ø±Ø¨ Ø§Ù„Ø´Ø§ÙŠØŒ Ø«Ù… Ø°Ù‡Ø¨Ù†Ø§ Ù„Ù„Ù†ÙˆÙ….
""",  # Grammar Score: 3 â€” mostly correct grammar, understandable, some repetitive or less polished phrasing

    "3": """
ÙÙŠ ØµØ¨Ø§Ø­ ÙŠÙˆÙ… Ø£Ù…Ø³ØŒ Ø®Ø±Ø¬ØªÙ Ø¨Ø±ÙÙ‚Ø© Ø£Ø®ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø³ÙˆÙ‚ Ù„Ø´Ø±Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø®Ø¶Ø±ÙˆØ§Øª ÙˆØ§Ù„ÙÙˆØ§ÙƒÙ‡ Ø§Ù„Ø·Ø§Ø²Ø¬Ø© Ø§Ø³ØªØ¹Ø¯Ø§Ø¯Ù‹Ø§ Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø¬Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø·Ù‡ÙŠ Ø§Ù„Ù…Ù†Ø²Ù„ÙŠ. ÙˆØ£Ø«Ù†Ø§Ø¡ Ø³ÙŠØ±Ù†Ø§ ÙÙŠ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø³Ø±ÙŠØ¹ØŒ ØªÙˆÙ‚ÙØª Ø³ÙŠØ§Ø±ØªÙ†Ø§ Ø¨Ø´ÙƒÙ„ Ù…ÙØ§Ø¬Ø¦ Ø¨Ø³Ø¨Ø¨ Ø®Ù„Ù„ Ù…ÙŠÙƒØ§Ù†ÙŠÙƒÙŠ ÙÙŠ Ø§Ù„Ù…Ø­Ø±Ùƒ. Ø­Ø§ÙˆÙ„Ù†Ø§ ØªÙ‡Ø¯Ø¦Ø© Ø§Ù„ÙˆØ¶Ø¹ ÙˆØ§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚ØŒ Ø§Ù„ØªÙŠ ÙˆØµÙ„Øª Ø¨Ø¹Ø¯ Ø«Ù„Ø§Ø«ÙŠÙ† Ø¯Ù‚ÙŠÙ‚Ø©. Ø¨Ø¹Ø¯ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø®Ù„Ù„ØŒ ÙˆØ§ØµÙ„Ù†Ø§ Ø·Ø±ÙŠÙ‚Ù†Ø§ Ù†Ø­Ùˆ Ø§Ù„Ø³ÙˆÙ‚ØŒ ÙˆØ£ÙƒÙ…Ù„Ù†Ø§ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø´Ø±Ø§Ø¡ Ø¨Ù‡Ø¯ÙˆØ¡. Ø¹Ù†Ø¯ Ø¹ÙˆØ¯ØªÙ†Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†Ø²Ù„ØŒ Ù‚Ù…Ù†Ø§ Ø¨ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§ØªØŒ Ø«Ù… Ø­Ø¶Ù‘Ø±Ù†Ø§ ÙˆØ¬Ø¨Ø© Ø®ÙÙŠÙØ©ØŒ ÙˆØ¬Ù„Ø³Ù†Ø§ Ù†ØªÙ†Ø§ÙˆÙ„Ù‡Ø§ Ø¨Ù‡Ø¯ÙˆØ¡ Ù‚Ø¨Ù„ Ø£Ù† Ù†Ø®Ù„Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ù†ÙˆÙ… Ù…Ø¨ÙƒØ±Ù‹Ø§ Ø¨Ø¹Ø¯ ÙŠÙˆÙ… Ù…Ù„ÙŠØ¡ Ø¨Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª.
"""   # Grammar Score: 5 â€” fluent MSA, cohesive paragraph, excellent use of connectors, consistent tense and proper structure
}
# Full Arabic test cases
arabic_test_cases2 = {
    "1": """
Ø¹Ù†ÙˆØ§Ù† Ø§Ø¹Ù„Ø§Ù† ÙŠÙƒÙˆÙ† Ø§Ø­Ø³Ù† ØªØ¬Ø±Ø¨Ø© ÙŠÙƒÙˆÙ† Ù‡Ø§ØªÙ Ù„Ù„Ù…Ø³ØªÙ‚Ø¨Ù„!

Ù‡Ùˆ ÙŠÙƒÙˆÙ† Ø§Ù†Øª ÙŠØ±ÙŠØ¯ Ø¬ÙˆØ§Ù„ Ø°ÙƒÙŠ ØªØºÙŠØ± Ø§Ù„Ø­ÙŠØ§Ø©ØŸ Ù„Ø§ Ø¨Ø­Ø« ÙƒÙ…Ø§Ù†! Ø¬ÙˆØ§Ù„ "Ø§Ù„ØªØ±Ø§ ØªÙƒÙ†Ù„ÙˆØ¬ÙŠ Ø¨Ø±Ùˆ" Ø¬Ø¯ÙŠØ¯ ÙŠØ¹Ø·ÙŠ ØªØ¬Ø±Ø¨Ø© Ù„Ø§ Ù…Ø«Ù„ Ù…Ø¹ Ø´Ø§Ø´Ø© Ø­Ù„ÙˆØ©ØŒ Ø§Ø¯Ø§Ø¡ ÙÙˆÙ‚ØŒ ÙˆØªØµÙ…ÙŠÙ… ÙƒÙˆÙŠØ³ ÙŠÙ…Ø³Ùƒ Ø§Ù„Ø¹ÙŠÙˆÙ†!

ØªØµÙˆÙŠØ± ØµÙˆØ± Ù…Ø´ Ø²ÙŠÙ‡Ø§ Ø¹Ø´Ø§Ù† ÙƒØ§Ù…ÙŠØ±Ø§ Ù‚ÙˆÙŠØ© ÙŠØ´ØªØºÙ„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ ØµÙ†Ø§Ø¹ÙŠØŒ Ø§Ù†Øª ÙŠÙ‚Ø¯Ø± ØªØ³ÙˆÙŠ ØªØµÙˆÙŠØ± Ø­Ù„Ùˆ Ù„Ø­Ø¸Ø§Øª Ø¨Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠ ÙÙˆÙ‚ Ø§Ù„Ø®ÙŠØ§Ù„!

Ø¨Ø·Ø§Ø±ÙŠØ© ÙŠØ¹ÙŠØ´ ÙƒØªÙŠØ± â€“ Ù…Ø§ÙÙŠ Ø®ÙˆÙ Ø´Ø­Ù† Ø¬ÙˆØ§Ù„Ùƒ Ø§Ù„Ø­ÙŠÙ†! Ø¨Ø·Ø§Ø±ÙŠØ© Ø¬Ø¯ÙŠØ¯ ÙŠØ¹Ø·ÙŠÙƒ ÙˆÙ‚Øª ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ø´ØªØºØ§Ù„ Ø¨Ø¯ÙˆÙ† ÙŠÙˆÙ‚Ù.

Ø¹Ø±Ø¶ Ø®Ø§Øµ ÙˆÙ‚Øª Ù…Ø­Ø¯ÙˆØ¯! Ø®Ø° Ø®ØµÙ… 30% Ø§Ø°Ø§ Ø´Ø±Ø§Ø¡ Ø¯Ø­ÙŠÙ†! Ù„Ø§ ØªØ±ÙˆØ­ ÙØ±ØµØ©ØŒ ÙˆÙƒÙ† Ø§ÙˆÙ„ Ù†Ø§Ø³ ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ù‡Ø°Ø§!
""",
    "2": """
Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø§Ù„: ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ø§Ù„Ø£Ø±Ø¶ÙŠØ© Ø¹Ù„Ù‰ Ø­ÙŠØ§Ø© Ø§Ù„Ù†Ø§Ø³ Ø§Ù„ÙŠÙˆÙ…ÙŠØ©

Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ù‡ÙŠ Ù‚ÙˆØ© ØªØ¬Ø°Ø¨ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ØŒ ÙˆØªØ¹Ø¯ Ù…Ù† Ø§Ù„Ø¸ÙˆØ§Ù‡Ø± Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙŠ ÙŠØªØ­ÙƒÙ… ÙÙŠ Ø­Ø±ÙƒØ© Ø§Ù„ÙƒÙˆØ§ÙƒØ¨ ÙˆØ§Ù„Ø£Ø¬Ø±Ø§Ù…. Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© ØªÙ… Ø§ÙƒØªØ´Ø§ÙÙ‡Ø§ Ø£ÙˆÙ„ Ù…Ø±Ø© Ù…Ù† Ø§Ù„Ø¹Ø§Ù„Ù… Ø¥Ø³Ø­Ø§Ù‚ Ù†ÙŠÙˆØªÙ†ØŒ Ù‡Ùˆ ÙˆØ¶Ø¹ Ø£Ø³Ø§Ø³ Ù„ÙÙ‡Ù…Ù†Ø§ Ø§Ù„Ø¹Ù„Ù…ÙŠ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù‚ÙˆØ©.

Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© ØªÙ„Ø¹Ø¨ Ø¯ÙˆØ± ÙƒØ¨ÙŠØ± ÙÙŠ ØªØ«Ø¨ÙŠØª Ø§Ù„ØºÙ„Ø§Ù Ø§Ù„Ø¬ÙˆÙŠØŒ Ø­ÙŠØ« ØªØ­ÙØ¸ Ø§Ù„Ù‡ÙˆØ§Ø¡ Ù…Ù† Ø§Ù„Ø°Ù‡Ø§Ø¨ Ø¥Ù„Ù‰ Ø§Ù„ÙØ¶Ø§Ø¡. ÙƒØ°Ù„ÙƒØŒ ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯ ÙˆØ§Ù„Ø¬Ø²Ø± ÙÙŠ Ø§Ù„Ø¨Ø­Ø± ÙˆØ§Ù„Ù…Ø­ÙŠØ·Ø§ØªØŒ ÙˆÙ‡Ø°Ø§ ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ ØªØºÙŠÙŠØ± ÙÙŠ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…ÙŠØ§Ù‡ Ù†ØªÙŠØ¬Ø© Ø¬Ø§Ø°Ø¨ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø±Ø¶ ÙˆØ§Ù„Ù‚Ù…Ø±.

ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©ØŒ Ù†Ø­Ø³ Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© ÙˆÙ‚Øª Ø§Ù„Ù…Ø´ÙŠ Ø£Ùˆ Ø§Ù„Ù‚ÙØ² Ø£Ùˆ ÙˆÙ‚Øª ÙˆÙ‚ÙˆØ¹ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡. Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ©ØŒ ØµØ¹Ø¨ Ø£Ù† Ù†Ø¹ÙŠØ´ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ØŒ ÙˆØ§Ù„Ø­Ø±ÙƒØ© ØªÙƒÙˆÙ† Ù…Ø«Ù„ Ø±ÙˆØ§Ø¯ Ø§Ù„ÙØ¶Ø§Ø¡ ÙˆÙ‚Øª Ø§Ù†Ø¹Ø¯Ø§Ù… Ø§Ù„ÙˆØ²Ù†.

Ø¨Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ©ØŒ ÙÙŠ ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø¸ÙˆØ§Ù‡Ø± Ù…Ø§Ø²Ø§Ù„Øª ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…Ø© ØªÙ…Ø§Ù…Ù‹Ø§. Ù…Ø«Ù„Ø§Ù‹ØŒ Ø§Ù„Ø¹Ù„Ù…Ø§Ø¡ ÙŠØ¯Ø±Ø³ÙˆÙ† ØªÙØ§Ø¹Ù„ Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ù…Ø¹ Ø§Ù„Ù‚ÙˆÙ‰ Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡ØŒ ÙˆØ¥Ø°Ø§ Ù…Ù…ÙƒÙ† Ù†Ø³ØªØ¹Ù…Ù„Ù‡Ø§ Ù…Ø³ØªÙ‚Ø¨Ù„Ù‹Ø§ ÙÙŠ Ø£Ø´ÙŠØ§Ø¡ Ø¹Ù„Ù…ÙŠØ© Ø£Ùˆ ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ©.
""",
    "3": """
Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¯Ø±Ø³: Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© â€“ Ù…ÙƒÙˆÙ†Ø§ØªÙ‡Ø§ ÙˆÙ‚ÙˆØ§Ù†ÙŠÙ†Ù‡Ø§ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©
Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ù‡ÙŠ Ù…Ø³Ø§Ø± Ù…ØºÙ„Ù‚ ÙŠØªØ¯ÙÙ‚ Ù…Ù† Ø®Ù„Ø§Ù„Ù‡ Ø§Ù„ØªÙŠØ§Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ù†ØªÙŠØ¬Ø© ÙˆØ¬ÙˆØ¯ ÙØ±Ù‚ Ø¬Ù‡Ø¯ Ø¨ÙŠÙ† Ø·Ø±ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ. ÙŠØªÙ… Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø³Ø±ÙŠØ§Ù† Ø§Ù„ØªÙŠØ§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒÙˆÙ†Ø§Øª Ù…Ø«Ù„ Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø§ØªØŒ Ø§Ù„Ù…ÙƒØ«ÙØ§ØªØŒ Ø§Ù„Ù…Ù„ÙØ§ØªØŒ ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©. ØªÙØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© ÙÙŠ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©ØŒ Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø·Ø§Ù‚Ø©ØŒ Ø§Ù„Ø³ÙŠØ§Ø±Ø§ØªØŒ ÙˆØ§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© Ø§Ù„Ø£Ø®Ø±Ù‰.

2. Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©
ØªØªÙƒÙˆÙ‘Ù† Ø£ÙŠ Ø¯Ø§Ø¦Ø±Ø© ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ©:

- Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ (Ù…Ø«Ù„ Ø§Ù„Ø¨Ø·Ø§Ø±ÙŠØ© Ø£Ùˆ Ø§Ù„Ù…ÙˆÙ„Ù‘Ø¯ Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ) Ø§Ù„Ø°ÙŠ ÙŠÙˆÙÙ‘Ø± Ø§Ù„Ø¬Ù‡Ø¯ Ø§Ù„Ù„Ø§Ø²Ù… Ù„ØªØ¯ÙÙ‚ Ø§Ù„ØªÙŠØ§Ø±.
- Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„ØªÙŠ ØªØ­Ø¯Ù‘ Ù…Ù† ØªØ¯ÙÙ‚ Ø§Ù„ØªÙŠØ§Ø± ÙˆØªØªØ­ÙƒÙ… ÙÙŠ ØªÙˆØ²ÙŠØ¹Ù‡.
- Ø§Ù„Ù…ÙƒØ«ÙØ§Øª Ø§Ù„ØªÙŠ ØªØ®Ø²Ù‘Ù† Ø§Ù„Ø´Ø­Ù†Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ù„ÙØªØ±Ø© Ù‚ØµÙŠØ±Ø© ÙˆØªÙØ³ØªØ®Ø¯Ù… ÙÙŠ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØªÙŠØ§Ø± ÙˆØ§Ù„Ø¬Ù‡Ø¯.
- Ø§Ù„Ù…Ù„ÙÙ‘Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„ØªÙŠ ØªÙØ³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„Ø­Ø«Ù‘ÙŠØ© ÙˆØ§Ù„Ù…ÙˆÙ„Ù‘Ø¯Ø§Øª ÙˆØ§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©.
- Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ø§Ù„Ø°ÙŠ ÙŠØªØ­ÙƒÙ… ÙÙŠ ÙØªØ­ Ø£Ùˆ ØºÙ„Ù‚ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø©.
- Ø§Ù„Ø£Ø³Ù„Ø§Ùƒ Ø§Ù„Ù…ÙˆØµÙ„Ø© Ø§Ù„ØªÙŠ ØªÙ†Ù‚Ù„ Ø§Ù„ØªÙŠØ§Ø± Ø¨ÙŠÙ† Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù„Ù„Ø¯Ø§Ø¦Ø±Ø©.

3. Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©
ØªØ¹ØªÙ…Ø¯ Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ù†ÙŠÙ† ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ©ØŒ Ù…Ù†Ù‡Ø§:

Ø£ÙˆÙ„Ù‹Ø§: Ù‚Ø§Ù†ÙˆÙ† Ø£ÙˆÙ…
ÙŠÙ†Øµ Ù‚Ø§Ù†ÙˆÙ† Ø£ÙˆÙ… Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù‡Ø¯ (V) ÙˆØ§Ù„ØªÙŠØ§Ø± (I) ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© (R) ÙÙŠ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© ØªÙØ¹Ø·Ù‰ Ø¨Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:
V = I Ã— R
Ø­ÙŠØ«:
- V Ù‡Ùˆ ÙØ±Ù‚ Ø§Ù„Ø¬Ù‡Ø¯ (Ø¨Ø§Ù„ÙÙˆÙ„Øª).
- I Ù‡Ùˆ Ø§Ù„ØªÙŠØ§Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ (Ø¨Ø§Ù„Ø£Ù…Ø¨ÙŠØ±).
- R Ù‡ÙŠ Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© (Ø¨Ø§Ù„Ø£ÙˆÙ…).

Ø«Ø§Ù†ÙŠÙ‹Ø§: Ù‚ÙˆØ§Ù†ÙŠÙ† ÙƒÙŠØ±Ø´ÙˆÙ
ØªÙØ³ØªØ®Ø¯Ù… Ù‚ÙˆØ§Ù†ÙŠÙ† ÙƒÙŠØ±Ø´ÙˆÙ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ù‘Ø¯Ø©ØŒ ÙˆØªØ´Ù…Ù„:
- Ù‚Ø§Ù†ÙˆÙ† ÙƒÙŠØ±Ø´ÙˆÙ Ù„Ù„ØªÙŠØ§Ø± (KCL): Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¯Ø§Ø®Ù„Ø© Ø¥Ù„Ù‰ Ø£ÙŠ Ù†Ù‚Ø·Ø© ØªÙØ±Ù‘Ø¹ ÙÙŠ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© ÙŠØ³Ø§ÙˆÙŠ Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ø®Ø§Ø±Ø¬Ø© Ù…Ù†Ù‡Ø§.
- Ù‚Ø§Ù†ÙˆÙ† ÙƒÙŠØ±Ø´ÙˆÙ Ù„Ù„Ø¬Ù‡Ø¯ (KVL): Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ø¬Ù‡ÙˆØ¯ Ø­ÙˆÙ„ Ø£ÙŠ Ù…Ø³Ø§Ø± Ù…ØºÙ„Ù‚ ÙÙŠ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© ÙŠØ³Ø§ÙˆÙŠ ØµÙØ±Ù‹Ø§.

4. ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
- Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø§Ù„Ù…Ù†Ø²Ù„ÙŠØ©: ØªÙØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ù„ØªÙˆØµÙŠÙ„ Ø§Ù„Ù…ØµØ§Ø¨ÙŠØ­ ÙˆØ§Ù„ØªØ­ÙƒÙ… ÙÙŠ ØªØ´ØºÙŠÙ„Ù‡Ø§.
- Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©: Ù…Ø«Ù„ Ø§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ù…Ø­Ù…ÙˆÙ„Ø© ÙˆØ£Ø¬Ù‡Ø²Ø© Ø§Ù„ÙƒÙ…Ø¨ÙŠÙˆØªØ± Ø§Ù„ØªÙŠ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¯ÙˆØ§Ø¦Ø± Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© Ù…Ø¹Ù‚Ù‘Ø¯Ø©.
- Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ù…ØªØ¬Ø¯Ø¯Ø©: ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ø­ Ø§Ù„Ø´Ù…Ø³ÙŠØ© ÙˆØ§Ù„Ù…Ø­ÙˆÙ„Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø¯ÙˆØ§Ø¦Ø± Ù…ØªÙ‚Ø¯Ù‘Ù…Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø´Ù…Ø³ÙŠØ© Ø¥Ù„Ù‰ ÙƒÙ‡Ø±Ø¨Ø§Ø¡ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù….
- Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©: ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¯ÙˆØ§Ø¦Ø± ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª ÙˆØ§Ù„Ø¨Ø·Ø§Ø±ÙŠØ§Øª ÙˆØ£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù…Ø§Ù†.

5. ØªÙ…Ø±ÙŠÙ† ØªØ·Ø¨ÙŠÙ‚ÙŠ:
Ø§Ù„Ø³Ø¤Ø§Ù„: Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ø¯Ø§Ø¦Ø±Ø© ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ø·Ø§Ø±ÙŠØ© Ø¬Ù‡Ø¯Ù‡Ø§ 12 ÙÙˆÙ„Øª ÙˆÙ…Ù‚Ø§ÙˆÙ…Ø© Ù…Ù‚Ø¯Ø§Ø±Ù‡Ø§ 4 Ø£ÙˆÙ…ØŒ Ø§Ø­Ø³Ø¨ Ù…Ù‚Ø¯Ø§Ø± Ø§Ù„ØªÙŠØ§Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø§Ø± ÙÙŠ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ù†ÙˆÙ† Ø£ÙˆÙ….
Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
I = V / R = 12 Ã· 4 = 3 Ø£Ù…Ø¨ÙŠØ±.

Ø®Ø§ØªÙ…Ø©:
ØªÙØ¹Ø¯ Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ© Ø£Ø³Ø§Ø³ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ø§Ù„ØªÙŠ Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„ÙŠÙ‡Ø§ ÙŠÙˆÙ…ÙŠÙ‹Ø§ØŒ Ø¨Ø¯Ø¡Ù‹Ø§ Ù…Ù† Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ù†Ø²Ù„ÙŠØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø© ÙˆØ­ØªÙ‰ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù‘Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª Ø§Ù„ÙØ¶Ø§Ø¦ÙŠØ©. Ø¥Ù† ÙÙ‡Ù… Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø«Ù„ Ù‚Ø§Ù†ÙˆÙ† Ø£ÙˆÙ… ÙˆÙ‚ÙˆØ§Ù†ÙŠÙ† ÙƒÙŠØ±Ø´ÙˆÙ ÙŠÙ…ÙƒÙ‘Ù† Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ÙŠÙ† Ù…Ù† ØªØµÙ…ÙŠÙ… Ø¯ÙˆØ§Ø¦Ø± Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© ÙˆØ§Ø¨ØªÙƒØ§Ø± ØªÙ‚Ù†ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø·Ø§Ù‚Ø© ÙˆØ§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª.
"""
}

def compute_lexical_diversity_score(text):
    text_clean = re.sub(rf"[{string.punctuation}]", "", text)
    words = wordpunct_tokenize(text_clean)
    if "ØŸ" in text_clean:
        sentences = text_clean.split("ØŸ")
    elif "Û”" in text_clean:
        sentences = text_clean.split("Û”")
    elif "." in text_clean:
        sentences = text_clean.split(".")
    else:
        sentences = text_clean.splitlines()

    num_words = len(words)
    num_sentences = len([s for s in sentences if s.strip()]) or 1
    vocab_size = len(set(words))
    type_token_ratio = vocab_size / num_words


    score = 0

    if type_token_ratio > 0.3:
        score += 1
    if vocab_size > num_words * 0.5:
        score += 1
    return {
        "type_token_ratio": type_token_ratio,
        "vocab_size": vocab_size,
        "lexical_score_out_of_2": score
    }


def compute_readability_metrics(text):
    # Remove punctuation
    text_clean = re.sub(rf"[{string.punctuation}ØŒØ›ØŸ]", "", text)

    # Tokenize
    words = wordpunct_tokenize(text_clean)
    sentences = nltk.sent_tokenize(text)
    num_sentences = len(sentences) or 1
    num_words = len(words) or 1
    num_chars = sum(len(word) for word in words)

    avg_sentence_length = num_words / num_sentences
    avg_word_length = num_chars / num_words

    # Arabic "complex word" approximation (words â‰¥ 6 letters)
    complex_words = [word for word in words if len(word) >= 6]
    complex_word_ratio = len(complex_words) / num_words

    return {
        "avg_sentence_length": avg_sentence_length,
        "avg_word_length": avg_word_length,
        "complex_word_ratio": complex_word_ratio
    }

def score_readability_metrics(readability):
    scores = {}

    # Avg sentence length
    asl = readability["avg_sentence_length"]
    if asl <= 12:
        scores["avg_sentence_length_score"] = 2
    elif 13 <= asl <= 20:
        scores["avg_sentence_length_score"] = 1
    else:
        scores["avg_sentence_length_score"] = 0

    # Avg word length
    awl = readability["avg_word_length"]
    if awl <= 4.0:
        scores["avg_word_length_score"] = 2
    elif 4.1 <= awl <= 5.5:
        scores["avg_word_length_score"] = 1
    else:
        scores["avg_word_length_score"] = 0

    # Complex word ratio
    cwr = readability["complex_word_ratio"]
    if cwr <= 0.20:
        scores["complex_word_ratio_score"] = 2
    elif 0.21 <= cwr <= 0.35:
        scores["complex_word_ratio_score"] = 1
    else:
        scores["complex_word_ratio_score"] = 0

    # Total score (out of 6)
    scores["total_readability_score"] = (
        scores["avg_sentence_length_score"]
        + scores["avg_word_length_score"]
        + scores["complex_word_ratio_score"]
    )

    return scores



def extract_grammar_score(output):  # ğŸ‘ˆ Add this
    import re
    match = re.search(r"Ø¯Ø±Ø¬Ø© Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙˆØ§Ù„ÙØµØ§Ø­Ø©:\s*(\d(?:\.\d)?)\s*/\s*5", output)
    return float(match.group(1)) if match else None


dash_line = "-" * 100

# Iterate through models
for model_name in model_names:
    print(f"\n{dash_line}\nTESTING MODEL: {model_name}\n{dash_line}")

    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    tokenizer.pad_token = tokenizer.eos_token
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True,
        token=os.environ["HF_TOKEN"]
    )

    # ğŸ’¡ Use same model for grammar scoring
    llama_tokenizer = tokenizer
    llama_model = model

    for label, example in arabic_test_cases2.items():
        print(f"\n{dash_line}\nINPUT ({label}):\n{example}\n{dash_line}")

        edu_prompt = f"""
ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ù…Ù‚ØªØ·Ù Ù†ØµÙŠØŒ Ù‚Ù… Ø¨ØªÙ‚ÙŠÙŠÙ… Ù…Ø¯Ù‰ ÙØ§Ø¦Ø¯ØªÙ‡ ÙƒÙ…Ø­ØªÙˆÙ‰ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… ØªÙ‚ÙŠÙŠÙ… Ù…ÙƒÙˆÙ† Ù…Ù† 5 Ù†Ù‚Ø§Ø· ØªØ±Ø§ÙƒÙ…ÙŠØ©ØŒ ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ§Ù„ÙŠØ©:

1 Ù†Ù‚Ø·Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©ØŒ Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ÙŠÙƒÙ† Ù‡Ø¯ÙÙ‡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø£Ùˆ Ø§Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ Ø¹Ù†Ø§ØµØ± ØºÙŠØ± Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØªØ±ÙˆÙŠØ¬ÙŠØ©.
2 Ù†Ù‚Ø§Ø·: Ø¥Ø°Ø§ ØªÙ†Ø§ÙˆÙ„ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¶ Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆÙ„ÙƒÙ†Ù‡ ØºÙŠØ± Ù…ØªØ¹Ù…Ù‚ Ø£Ùˆ Ù‚Ø¯ ÙŠØ®Ù„Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ø¹Ù†Ø§ØµØ± ØºÙŠØ± Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©ØŒ Ø£Ùˆ ÙŠÙ‚Ø¯Ù… Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¨Ø³ÙŠØ·Ø© Ø¯ÙˆÙ† ØªÙ†Ø¸ÙŠÙ… ÙˆØ§Ø¶Ø­.
3 Ù†Ù‚Ø§Ø·: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØŒ ÙˆÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ÙØ§Ù‡ÙŠÙ… Ø£Ø³Ø§Ø³ÙŠØ© Ø°Ø§Øª ØµÙ„Ø© Ø¨Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©ØŒ Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ÙŠÙƒÙ† Ø´Ø§Ù…Ù„Ø§Ù‹ ØªÙ…Ø§Ù…Ù‹Ø§ Ø£Ùˆ Ø§Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©.
4 Ù†Ù‚Ø§Ø·: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ù…Ù†Ø¸Ù…Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ØŒ ÙˆÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙƒÙ…Ø±Ø¬Ø¹ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø¬ÙŠØ¯. ÙŠØ´Ø¨Ù‡ Ù…Ø­ØªÙˆÙ‰ ÙƒØªØ§Ø¨ Ø¯Ø±Ø§Ø³ÙŠ Ø£Ùˆ Ø¯Ø±Ø³ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ù…Ø¨Ø³Ø·ØŒ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ù…Ø«Ù„Ø© ÙˆØ§Ù„ØªÙ…Ø§Ø±ÙŠÙ†ØŒ Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø¨Ø¹Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©.
5 Ù†Ù‚Ø§Ø·: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø© ØªØ¹Ù„ÙŠÙ…ÙŠÙ‹Ø§ØŒ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø´Ø§Ù…Ù„ØŒ Ø¨Ø´Ø±ÙˆØ­Ø§Øª ÙˆØ§Ø¶Ø­Ø©ØŒ ÙˆØ£Ù…Ø«Ù„Ø© ÙˆØªÙ…Ø§Ø±ÙŠÙ† ØªØ¬Ø¹Ù„Ù‡ Ù…Ù†Ø§Ø³Ø¨Ù‹Ø§ ØªÙ…Ø§Ù…Ù‹Ø§ ÙƒÙ…ØµØ¯Ø± ØªØ¹Ù„ÙŠÙ…ÙŠ Ø±Ø³Ù…ÙŠ. ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Øµ Ù…ØªÙƒØ§Ù…Ù„Ø§Ù‹ ÙˆØ®Ø§Ù„ÙŠÙ‹Ø§ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ© Ø£Ùˆ Ø§Ù„ØªÙƒØ±Ø§Ø± ØºÙŠØ± Ø§Ù„Ù…ÙÙŠØ¯.
Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªÙ‚ÙŠÙŠÙ…Ù‡:
{example}

Ø¨Ø¹Ø¯ ÙØ­Øµ Ø§Ù„Ù…Ù‚ØªØ·Ù:

ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠ ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­:
"Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ: <Ø±Ù‚Ù… Ù…Ù† 0 Ø¥Ù„Ù‰ 5> / 5"
        """

        grammar_prompt = f"""
ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ù…Ù‚ØªØ·Ù Ù†ØµÙŠØŒ Ø±Ø¬Ø§Ø¡Ù‹ Ù‚ÙŠÙ‘Ù… Ø¬ÙˆØ¯Ø© Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ© ÙˆÙØµØ§Ø­Ø© Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø¨Ø´ÙƒÙ„ ØµØ§Ø±Ù… ÙˆØ¯Ù‚ÙŠÙ‚ØŒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù‚ÙŠØ§Ø³ Ù…Ù† 0 Ø¥Ù„Ù‰ 5. Ø®Ø° ÙÙŠ Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ§Ù„ÙŠØ©:

- Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­Ùˆ (Ù…Ø«Ù„ Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ØŒ Ø§Ù„Ø£Ø²Ù…Ù†Ø©ØŒ Ø§Ù„ØªØ°ÙƒÙŠØ± ÙˆØ§Ù„ØªØ£Ù†ÙŠØ«ØŒ Ø§Ù„ØªØ±Ø§ÙƒÙŠØ¨)
- ÙˆØ¶ÙˆØ­ ÙˆØªÙ…Ø§Ø³Ùƒ Ø§Ù„Ø¬Ù…Ù„
- Ø®Ù„Ùˆ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ù„ØºÙˆÙŠØ©
- ØªØ±Ø§Ø¨Ø· Ø§Ù„Ø£ÙÙƒØ§Ø± ÙˆØ³Ù„Ø§Ø³Ø© Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨ÙŠÙ†Ù‡Ø§
- Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø¬Ù…Ù„ ÙˆØ§Ù„ÙÙ‚Ø±Ø§Øª

ğŸ›‘ Ø¥Ø°Ø§ Ø§Ø­ØªÙˆÙ‰ Ø§Ù„Ù†Øµ Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù† Ø§Ù„Ø¢ØªÙŠØŒ ÙŠØ¬Ø¨ ØªØ®ÙÙŠØ¶ Ø§Ù„Ø¯Ø±Ø¬Ø©:
- Ù„ØºØ© Ø¹Ø§Ù…ÙŠØ© Ø£Ùˆ Ø¯Ø¹Ø§Ø¦ÙŠØ© ØºÙŠØ± ÙØµÙŠØ­Ø©
- Ø¬Ù…Ù„ ØºÙŠØ± Ø³Ù„ÙŠÙ…Ø© Ù†Ø­ÙˆÙŠÙ‹Ø§
- ØºÙŠØ§Ø¨ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø£Ùˆ Ø¶Ø¹Ù Ø§Ù„ØªÙ†Ø¸ÙŠÙ…


Ø§Ù„Ù†Øµ:
{example}

ğŸ“Œ Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ØŒ ÙˆØ¨Ù†ÙØ³ Ø§Ù„ØµÙŠØºØ© Ø§Ù„ØªØ§Ù„ÙŠØ© ØªÙ…Ø§Ù…Ù‹Ø§ (Ù„Ø§ ØªØºÙŠÙ‘Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª):

"Ø¯Ø±Ø¬Ø© Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙˆØ§Ù„ÙØµØ§Ø­Ø©: <Ø±Ù‚Ù… Ù…Ù† 0 Ø¥Ù„Ù‰ 5> / 5"

"""

        gen_config = GenerationConfig(
            max_new_tokens=100,
            do_sample=True,
            temperature=0.7,
            top_p=0.9
        )

        # Run educational prompt
        edu_inputs = tokenizer(edu_prompt, return_tensors="pt", truncation=True, padding=True, max_length=2048).to(device)
        edu_inputs["attention_mask"] = (edu_inputs["input_ids"] != tokenizer.pad_token_id).to(device)
        edu_output = tokenizer.decode(
            model.generate(edu_inputs["input_ids"], attention_mask=edu_inputs["attention_mask"], generation_config=gen_config)[0],
            skip_special_tokens=True
        )

        # Run grammar prompt
        llama_inputs = llama_tokenizer(grammar_prompt, return_tensors="pt", truncation=True, padding=True, max_length=2048).to(device)
        llama_inputs["attention_mask"] = (llama_inputs["input_ids"] != llama_tokenizer.pad_token_id).to(device)
        grammar_output = llama_tokenizer.decode(
            llama_model.generate(llama_inputs["input_ids"], attention_mask=llama_inputs["attention_mask"], generation_config=gen_config)[0],
            skip_special_tokens=True
        )

        # Output
        print(f"ğŸ§  LLM Educational Raw Output:\n{edu_output}")
        print(f"ğŸ§  LLaMA Grammar Raw Output:\n{grammar_output}")

        # Try extracting grammar score
        grammar_score = extract_grammar_score(grammar_output)
        if grammar_score is not None:
            print(f"âœ… Extracted Grammar Score: {grammar_score} / 5")
        else:
            print("âŒ Failed to extract grammar score (unexpected format).")

        # Stats
        lexical_stats = compute_lexical_diversity_score(example)
        print(f"ğŸ”¤ Lexical Diversity Score: {lexical_stats['lexical_score_out_of_2']} / 2")
        print(f"   â†’ Type-Token Ratio: {lexical_stats['type_token_ratio']:.2f}")
        print(f"   â†’ Vocabulary Size: {lexical_stats['vocab_size']}")


        readability = compute_readability_metrics(example)
        readability_scores = score_readability_metrics(readability)

        print(f"ğŸ“– Readability Metrics:")
        print(f"   â†’ Avg Sentence Length: {readability['avg_sentence_length']:.2f}")
        print(f"   â†’ Avg Word Length: {readability['avg_word_length']:.2f}")
        print(f"   â†’ Complex Word Ratio: {readability['complex_word_ratio']:.2%}")
        print(f"ğŸ“ˆ Readability Score (out of 6): {readability_scores['total_readability_score']}")



# CLEANUP after both generations
del model
del tokenizer
torch.cuda.empty_cache()
gc.collect()


print(f"\n{dash_line}\nâœ… TESTING COMPLETE\n{dash_line}")

# Final cleanup of LLaMA model used for grammar
del llama_model
del llama_tokenizer
torch.cuda.empty_cache()
gc.collect()
